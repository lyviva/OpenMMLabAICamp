2023/02/10 22:51:39 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]
    CUDA available: True
    numpy_random_seed: 1072697605
    GPU 0: NVIDIA GeForce GTX 1060 6GB
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.3, V11.3.58
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
    PyTorch: 1.11.0+cu113
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.12.0+cu113
    OpenCV: 4.6.0
    MMEngine: 0.5.0

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: None
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2023/02/10 22:51:39 - mmengine - INFO - Config:
model = dict(
    type='FasterRCNN',
    data_preprocessor=dict(
        type='DetDataPreprocessor',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        bgr_to_rgb=True,
        pad_size_divisor=32),
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        style='pytorch',
        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    roi_head=dict(
        type='StandardRoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=dict(
            type='Shared2FCBBoxHead',
            in_channels=256,
            fc_out_channels=1024,
            roi_feat_size=7,
            num_classes=20,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            reg_class_agnostic=False,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=-1,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=False,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100)))
dataset_type = 'VOCDataset'
data_root = 'data/VOCdevkit/'
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(type='LoadImageFromFile', file_client_args=dict(backend='disk')),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', scale=(1000, 600), keep_ratio=True),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PackDetInputs')
]
test_pipeline = [
    dict(type='LoadImageFromFile', file_client_args=dict(backend='disk')),
    dict(type='Resize', scale=(1000, 600), keep_ratio=True),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='PackDetInputs',
        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                   'scale_factor'))
]
train_dataloader = dict(
    batch_size=4,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    batch_sampler=dict(type='AspectRatioBatchSampler'),
    dataset=dict(
        type='RepeatDataset',
        times=3,
        dataset=dict(
            type='ConcatDataset',
            ignore_keys=['dataset_type'],
            datasets=[
                dict(
                    type='VOCDataset',
                    data_root='data/VOCdevkit/',
                    ann_file='VOC2012/ImageSets/Main/trainval.txt',
                    data_prefix=dict(sub_data_root='VOC2012/'),
                    filter_cfg=dict(
                        filter_empty_gt=True, min_size=32, bbox_min_size=32),
                    pipeline=[
                        dict(
                            type='LoadImageFromFile',
                            file_client_args=dict(backend='disk')),
                        dict(type='LoadAnnotations', with_bbox=True),
                        dict(
                            type='Resize', scale=(1000, 600), keep_ratio=True),
                        dict(type='RandomFlip', prob=0.5),
                        dict(type='PackDetInputs')
                    ]),
                dict(
                    type='VOCDataset',
                    data_root='data/VOCdevkit/',
                    ann_file='VOC2012/ImageSets/Main/trainval.txt',
                    data_prefix=dict(sub_data_root='VOC2012/'),
                    filter_cfg=dict(
                        filter_empty_gt=True, min_size=32, bbox_min_size=32),
                    pipeline=[
                        dict(
                            type='LoadImageFromFile',
                            file_client_args=dict(backend='disk')),
                        dict(type='LoadAnnotations', with_bbox=True),
                        dict(
                            type='Resize', scale=(1000, 600), keep_ratio=True),
                        dict(type='RandomFlip', prob=0.5),
                        dict(type='PackDetInputs')
                    ])
            ])))
val_dataloader = dict(
    batch_size=1,
    num_workers=2,
    persistent_workers=True,
    drop_last=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='VOCDataset',
        data_root='data/VOCdevkit/',
        ann_file='VOC2012/ImageSets/Main/val.txt',
        data_prefix=dict(sub_data_root='VOC2012/'),
        test_mode=True,
        pipeline=[
            dict(
                type='LoadImageFromFile',
                file_client_args=dict(backend='disk')),
            dict(type='Resize', scale=(1000, 600), keep_ratio=True),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                type='PackDetInputs',
                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                           'scale_factor'))
        ]))
test_dataloader = dict(
    batch_size=1,
    num_workers=2,
    persistent_workers=True,
    drop_last=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='VOCDataset',
        data_root='data/VOCdevkit/',
        ann_file='VOC2012/ImageSets/Main/val.txt',
        data_prefix=dict(sub_data_root='VOC2012/'),
        test_mode=True,
        pipeline=[
            dict(
                type='LoadImageFromFile',
                file_client_args=dict(backend='disk')),
            dict(type='Resize', scale=(1000, 600), keep_ratio=True),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                type='PackDetInputs',
                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                           'scale_factor'))
        ]))
val_evaluator = dict(type='VOCMetric', metric='mAP', eval_mode='11points')
test_evaluator = dict(type='VOCMetric', metric='mAP', eval_mode='11points')
default_scope = 'mmdet'
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=50),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(type='CheckpointHook', interval=1),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(type='DetVisualizationHook'))
env_cfg = dict(
    cudnn_benchmark=False,
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl'))
vis_backends = [dict(type='LocalVisBackend')]
visualizer = dict(
    type='DetLocalVisualizer',
    vis_backends=[dict(type='LocalVisBackend')],
    name='visualizer')
log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)
log_level = 'INFO'
load_from = 'faster_rcnn_r50_fpn_1x_voc0712_20220320_192712-54bef0f3.pth'
resume = False
max_epochs = 1
train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=1, val_interval=1)
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')
param_scheduler = [
    dict(
        type='MultiStepLR',
        begin=0,
        end=1,
        by_epoch=True,
        milestones=[3],
        gamma=0.1)
]
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(type='SGD', lr=0.0002, momentum=0.9, weight_decay=0.0001))
auto_scale_lr = dict(enable=False, base_batch_size=16)
launcher = 'none'
work_dir = './work_dirs/faster-rcnn_r50_fpn_1x_voc0712'

2023/02/10 22:51:39 - mmengine - WARNING - The "visualizer" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:39 - mmengine - WARNING - The "vis_backend" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:39 - mmengine - WARNING - The "model" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:39 - mmengine - WARNING - The "task util" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:41 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2023/02/10 22:51:41 - mmengine - WARNING - The "hook" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:41 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/02/10 22:51:41 - mmengine - WARNING - The "loop" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:41 - mmengine - WARNING - The "dataset" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:41 - mmengine - WARNING - The "transform" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:42 - mmengine - WARNING - The "data sampler" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:42 - mmengine - WARNING - The "optimizer constructor" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:42 - mmengine - WARNING - The "optimizer" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:42 - mmengine - WARNING - The "optim_wrapper" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:42 - mmengine - WARNING - The "parameter scheduler" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:42 - mmengine - WARNING - The "metric" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:43 - mmengine - WARNING - The "weight initializer" registry in mmdet did not set import location. Fallback to call `mmdet.utils.register_all_modules` instead.
2023/02/10 22:51:43 - mmengine - INFO - load model from: torchvision://resnet50
2023/02/10 22:51:43 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
2023/02/10 22:51:43 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of FasterRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.weight - torch.Size([21, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.bias - torch.Size([21]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_reg.weight - torch.Size([80, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.fc_reg.bias - torch.Size([80]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 
2023/02/10 22:51:43 - mmengine - INFO - Load checkpoint from faster_rcnn_r50_fpn_1x_voc0712_20220320_192712-54bef0f3.pth
2023/02/10 22:51:43 - mmengine - INFO - Checkpoints will be saved to /home/liuyoufu/code/OpenMMLab/mmdetection/work_dirs/faster-rcnn_r50_fpn_1x_voc0712.
2023/02/10 22:52:31 - mmengine - INFO - Epoch(train) [1][   50/17310]  lr: 2.0000e-04  eta: 4:38:47  time: 0.9691  data_time: 0.0048  memory: 3969  loss: 0.2066  loss_rpn_cls: 0.0061  loss_rpn_bbox: 0.0092  loss_cls: 0.0777  acc: 99.2676  loss_bbox: 0.1136
2023/02/10 22:53:20 - mmengine - INFO - Epoch(train) [1][  100/17310]  lr: 2.0000e-04  eta: 4:39:15  time: 0.9781  data_time: 0.0031  memory: 4088  loss: 0.2012  loss_rpn_cls: 0.0066  loss_rpn_bbox: 0.0115  loss_cls: 0.0717  acc: 96.4844  loss_bbox: 0.1113
2023/02/10 22:54:09 - mmengine - INFO - Epoch(train) [1][  150/17310]  lr: 2.0000e-04  eta: 4:38:24  time: 0.9733  data_time: 0.0031  memory: 3969  loss: 0.2064  loss_rpn_cls: 0.0057  loss_rpn_bbox: 0.0102  loss_cls: 0.0742  acc: 96.3867  loss_bbox: 0.1164
2023/02/10 22:54:57 - mmengine - INFO - Epoch(train) [1][  200/17310]  lr: 2.0000e-04  eta: 4:37:32  time: 0.9725  data_time: 0.0031  memory: 3969  loss: 0.1926  loss_rpn_cls: 0.0049  loss_rpn_bbox: 0.0100  loss_cls: 0.0698  acc: 98.1445  loss_bbox: 0.1078
2023/02/10 22:55:46 - mmengine - INFO - Epoch(train) [1][  250/17310]  lr: 2.0000e-04  eta: 4:36:18  time: 0.9660  data_time: 0.0031  memory: 3969  loss: 0.2008  loss_rpn_cls: 0.0076  loss_rpn_bbox: 0.0117  loss_cls: 0.0731  acc: 97.8027  loss_bbox: 0.1084
2023/02/10 22:56:34 - mmengine - INFO - Epoch(train) [1][  300/17310]  lr: 2.0000e-04  eta: 4:35:24  time: 0.9699  data_time: 0.0029  memory: 3970  loss: 0.2268  loss_rpn_cls: 0.0053  loss_rpn_bbox: 0.0105  loss_cls: 0.0867  acc: 99.3652  loss_bbox: 0.1242
2023/02/10 22:57:23 - mmengine - INFO - Epoch(train) [1][  350/17310]  lr: 2.0000e-04  eta: 4:34:33  time: 0.9705  data_time: 0.0030  memory: 3969  loss: 0.2087  loss_rpn_cls: 0.0048  loss_rpn_bbox: 0.0095  loss_cls: 0.0751  acc: 94.6289  loss_bbox: 0.1194
2023/02/10 22:58:11 - mmengine - INFO - Epoch(train) [1][  400/17310]  lr: 2.0000e-04  eta: 4:33:33  time: 0.9657  data_time: 0.0029  memory: 3969  loss: 0.2138  loss_rpn_cls: 0.0056  loss_rpn_bbox: 0.0104  loss_cls: 0.0761  acc: 98.8770  loss_bbox: 0.1218
2023/02/10 22:59:00 - mmengine - INFO - Epoch(train) [1][  450/17310]  lr: 2.0000e-04  eta: 4:32:42  time: 0.9693  data_time: 0.0030  memory: 3969  loss: 0.2031  loss_rpn_cls: 0.0059  loss_rpn_bbox: 0.0099  loss_cls: 0.0736  acc: 97.1680  loss_bbox: 0.1138
2023/02/10 22:59:48 - mmengine - INFO - Epoch(train) [1][  500/17310]  lr: 2.0000e-04  eta: 4:31:46  time: 0.9663  data_time: 0.0029  memory: 4088  loss: 0.2068  loss_rpn_cls: 0.0053  loss_rpn_bbox: 0.0094  loss_cls: 0.0751  acc: 98.2910  loss_bbox: 0.1170
2023/02/10 23:00:37 - mmengine - INFO - Epoch(train) [1][  550/17310]  lr: 2.0000e-04  eta: 4:31:06  time: 0.9752  data_time: 0.0030  memory: 4088  loss: 0.1995  loss_rpn_cls: 0.0057  loss_rpn_bbox: 0.0098  loss_cls: 0.0734  acc: 98.1445  loss_bbox: 0.1106
2023/02/10 23:01:25 - mmengine - INFO - Epoch(train) [1][  600/17310]  lr: 2.0000e-04  eta: 4:30:22  time: 0.9742  data_time: 0.0031  memory: 4212  loss: 0.2174  loss_rpn_cls: 0.0058  loss_rpn_bbox: 0.0104  loss_cls: 0.0773  acc: 98.0469  loss_bbox: 0.1239
2023/02/10 23:02:14 - mmengine - INFO - Epoch(train) [1][  650/17310]  lr: 2.0000e-04  eta: 4:29:28  time: 0.9662  data_time: 0.0030  memory: 3969  loss: 0.2136  loss_rpn_cls: 0.0059  loss_rpn_bbox: 0.0101  loss_cls: 0.0768  acc: 94.7266  loss_bbox: 0.1208
2023/02/10 23:03:02 - mmengine - INFO - Epoch(train) [1][  700/17310]  lr: 2.0000e-04  eta: 4:28:25  time: 0.9581  data_time: 0.0030  memory: 3969  loss: 0.2151  loss_rpn_cls: 0.0055  loss_rpn_bbox: 0.0104  loss_cls: 0.0750  acc: 98.2422  loss_bbox: 0.1242
2023/02/10 23:03:50 - mmengine - INFO - Epoch(train) [1][  750/17310]  lr: 2.0000e-04  eta: 4:27:40  time: 0.9732  data_time: 0.0030  memory: 3970  loss: 0.1964  loss_rpn_cls: 0.0052  loss_rpn_bbox: 0.0095  loss_cls: 0.0702  acc: 97.9004  loss_bbox: 0.1115
2023/02/10 23:04:41 - mmengine - INFO - Epoch(train) [1][  800/17310]  lr: 2.0000e-04  eta: 4:27:42  time: 1.0186  data_time: 0.0031  memory: 4088  loss: 0.1935  loss_rpn_cls: 0.0055  loss_rpn_bbox: 0.0095  loss_cls: 0.0691  acc: 98.1445  loss_bbox: 0.1094
2023/02/10 23:05:31 - mmengine - INFO - Epoch(train) [1][  850/17310]  lr: 2.0000e-04  eta: 4:27:18  time: 0.9989  data_time: 0.0031  memory: 4088  loss: 0.2036  loss_rpn_cls: 0.0048  loss_rpn_bbox: 0.0107  loss_cls: 0.0708  acc: 95.7031  loss_bbox: 0.1173
2023/02/10 23:06:21 - mmengine - INFO - Epoch(train) [1][  900/17310]  lr: 2.0000e-04  eta: 4:26:58  time: 1.0054  data_time: 0.0031  memory: 3969  loss: 0.1964  loss_rpn_cls: 0.0052  loss_rpn_bbox: 0.0101  loss_cls: 0.0719  acc: 97.8516  loss_bbox: 0.1092
2023/02/10 23:07:13 - mmengine - INFO - Epoch(train) [1][  950/17310]  lr: 2.0000e-04  eta: 4:26:56  time: 1.0303  data_time: 0.0032  memory: 3969  loss: 0.1745  loss_rpn_cls: 0.0049  loss_rpn_bbox: 0.0095  loss_cls: 0.0630  acc: 97.1191  loss_bbox: 0.0971
2023/02/10 23:08:03 - mmengine - INFO - Exp name: faster-rcnn_r50_fpn_1x_voc0712_20230210_225138
2023/02/10 23:08:03 - mmengine - INFO - Epoch(train) [1][ 1000/17310]  lr: 2.0000e-04  eta: 4:26:29  time: 1.0056  data_time: 0.0032  memory: 4088  loss: 0.1884  loss_rpn_cls: 0.0059  loss_rpn_bbox: 0.0092  loss_cls: 0.0647  acc: 97.4121  loss_bbox: 0.1086
2023/02/10 23:08:54 - mmengine - INFO - Epoch(train) [1][ 1050/17310]  lr: 2.0000e-04  eta: 4:26:06  time: 1.0139  data_time: 0.0032  memory: 4212  loss: 0.2137  loss_rpn_cls: 0.0072  loss_rpn_bbox: 0.0107  loss_cls: 0.0744  acc: 90.8691  loss_bbox: 0.1215
2023/02/10 23:09:44 - mmengine - INFO - Epoch(train) [1][ 1100/17310]  lr: 2.0000e-04  eta: 4:25:33  time: 1.0042  data_time: 0.0033  memory: 3969  loss: 0.2019  loss_rpn_cls: 0.0052  loss_rpn_bbox: 0.0095  loss_cls: 0.0703  acc: 98.6328  loss_bbox: 0.1169
2023/02/10 23:10:35 - mmengine - INFO - Epoch(train) [1][ 1150/17310]  lr: 2.0000e-04  eta: 4:25:13  time: 1.0247  data_time: 0.0033  memory: 4088  loss: 0.2034  loss_rpn_cls: 0.0048  loss_rpn_bbox: 0.0090  loss_cls: 0.0731  acc: 99.1211  loss_bbox: 0.1165
2023/02/10 23:11:25 - mmengine - INFO - Epoch(train) [1][ 1200/17310]  lr: 2.0000e-04  eta: 4:24:33  time: 0.9982  data_time: 0.0032  memory: 3970  loss: 0.1992  loss_rpn_cls: 0.0061  loss_rpn_bbox: 0.0100  loss_cls: 0.0739  acc: 95.2637  loss_bbox: 0.1092
2023/02/10 23:12:15 - mmengine - INFO - Epoch(train) [1][ 1250/17310]  lr: 2.0000e-04  eta: 4:23:45  time: 0.9877  data_time: 0.0032  memory: 3969  loss: 0.1779  loss_rpn_cls: 0.0045  loss_rpn_bbox: 0.0090  loss_cls: 0.0617  acc: 97.8027  loss_bbox: 0.1027
2023/02/10 23:13:04 - mmengine - INFO - Epoch(train) [1][ 1300/17310]  lr: 2.0000e-04  eta: 4:22:55  time: 0.9832  data_time: 0.0032  memory: 3969  loss: 0.1913  loss_rpn_cls: 0.0050  loss_rpn_bbox: 0.0086  loss_cls: 0.0691  acc: 97.8516  loss_bbox: 0.1086
2023/02/10 23:13:54 - mmengine - INFO - Epoch(train) [1][ 1350/17310]  lr: 2.0000e-04  eta: 4:22:17  time: 1.0050  data_time: 0.0033  memory: 3969  loss: 0.1948  loss_rpn_cls: 0.0046  loss_rpn_bbox: 0.0095  loss_cls: 0.0675  acc: 96.1914  loss_bbox: 0.1133
2023/02/10 23:14:45 - mmengine - INFO - Epoch(train) [1][ 1400/17310]  lr: 2.0000e-04  eta: 4:21:44  time: 1.0149  data_time: 0.0033  memory: 3970  loss: 0.2093  loss_rpn_cls: 0.0061  loss_rpn_bbox: 0.0100  loss_cls: 0.0730  acc: 95.1660  loss_bbox: 0.1202
2023/02/10 23:15:36 - mmengine - INFO - Epoch(train) [1][ 1450/17310]  lr: 2.0000e-04  eta: 4:21:12  time: 1.0182  data_time: 0.0034  memory: 3969  loss: 0.1787  loss_rpn_cls: 0.0043  loss_rpn_bbox: 0.0092  loss_cls: 0.0652  acc: 97.5098  loss_bbox: 0.1000
2023/02/10 23:16:27 - mmengine - INFO - Epoch(train) [1][ 1500/17310]  lr: 2.0000e-04  eta: 4:20:43  time: 1.0279  data_time: 0.0032  memory: 3969  loss: 0.2047  loss_rpn_cls: 0.0055  loss_rpn_bbox: 0.0105  loss_cls: 0.0748  acc: 97.9980  loss_bbox: 0.1138
2023/02/10 23:17:19 - mmengine - INFO - Epoch(train) [1][ 1550/17310]  lr: 2.0000e-04  eta: 4:20:24  time: 1.0495  data_time: 0.0033  memory: 4088  loss: 0.1905  loss_rpn_cls: 0.0042  loss_rpn_bbox: 0.0084  loss_cls: 0.0695  acc: 99.3652  loss_bbox: 0.1084
2023/02/10 23:18:13 - mmengine - INFO - Epoch(train) [1][ 1600/17310]  lr: 2.0000e-04  eta: 4:20:15  time: 1.0745  data_time: 0.0034  memory: 3969  loss: 0.1999  loss_rpn_cls: 0.0049  loss_rpn_bbox: 0.0106  loss_cls: 0.0691  acc: 98.8770  loss_bbox: 0.1152
2023/02/10 23:19:03 - mmengine - INFO - Epoch(train) [1][ 1650/17310]  lr: 2.0000e-04  eta: 4:19:22  time: 0.9860  data_time: 0.0033  memory: 3969  loss: 0.2060  loss_rpn_cls: 0.0055  loss_rpn_bbox: 0.0096  loss_cls: 0.0730  acc: 97.7051  loss_bbox: 0.1178
2023/02/10 23:19:54 - mmengine - INFO - Epoch(train) [1][ 1700/17310]  lr: 2.0000e-04  eta: 4:18:53  time: 1.0381  data_time: 0.0033  memory: 3969  loss: 0.2088  loss_rpn_cls: 0.0047  loss_rpn_bbox: 0.0094  loss_cls: 0.0772  acc: 97.9980  loss_bbox: 0.1175
2023/02/10 23:20:45 - mmengine - INFO - Epoch(train) [1][ 1750/17310]  lr: 2.0000e-04  eta: 4:18:14  time: 1.0201  data_time: 0.0032  memory: 3969  loss: 0.2364  loss_rpn_cls: 0.0053  loss_rpn_bbox: 0.0109  loss_cls: 0.0847  acc: 94.7266  loss_bbox: 0.1355
2023/02/10 23:21:36 - mmengine - INFO - Epoch(train) [1][ 1800/17310]  lr: 2.0000e-04  eta: 4:17:31  time: 1.0121  data_time: 0.0033  memory: 4212  loss: 0.2178  loss_rpn_cls: 0.0049  loss_rpn_bbox: 0.0108  loss_cls: 0.0800  acc: 95.6543  loss_bbox: 0.1221
2023/02/10 23:22:27 - mmengine - INFO - Epoch(train) [1][ 1850/17310]  lr: 2.0000e-04  eta: 4:16:54  time: 1.0259  data_time: 0.0033  memory: 3970  loss: 0.2334  loss_rpn_cls: 0.0060  loss_rpn_bbox: 0.0111  loss_cls: 0.0836  acc: 92.7734  loss_bbox: 0.1327
2023/02/10 23:23:17 - mmengine - INFO - Epoch(train) [1][ 1900/17310]  lr: 2.0000e-04  eta: 4:16:03  time: 0.9945  data_time: 0.0032  memory: 4088  loss: 0.1919  loss_rpn_cls: 0.0053  loss_rpn_bbox: 0.0094  loss_cls: 0.0700  acc: 97.9004  loss_bbox: 0.1072
2023/02/10 23:24:07 - mmengine - INFO - Epoch(train) [1][ 1950/17310]  lr: 2.0000e-04  eta: 4:15:12  time: 0.9941  data_time: 0.0032  memory: 4088  loss: 0.2070  loss_rpn_cls: 0.0043  loss_rpn_bbox: 0.0099  loss_cls: 0.0740  acc: 98.3887  loss_bbox: 0.1188
2023/02/10 23:24:58 - mmengine - INFO - Exp name: faster-rcnn_r50_fpn_1x_voc0712_20230210_225138
2023/02/10 23:24:58 - mmengine - INFO - Epoch(train) [1][ 2000/17310]  lr: 2.0000e-04  eta: 4:14:33  time: 1.0252  data_time: 0.0033  memory: 3969  loss: 0.2215  loss_rpn_cls: 0.0043  loss_rpn_bbox: 0.0093  loss_cls: 0.0786  acc: 99.0234  loss_bbox: 0.1293
