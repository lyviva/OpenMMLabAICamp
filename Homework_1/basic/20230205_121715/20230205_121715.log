2023/02/05 12:17:16 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.13 (default, Oct 21 2022, 23:50:54) [GCC 11.2.0]
    CUDA available: True
    numpy_random_seed: 676323602
    GPU 0: NVIDIA GeForce GTX 1060 6GB
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.3, V11.3.58
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
    PyTorch: 1.12.0+cu113
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.13.0+cu113
    OpenCV: 4.6.0
    MMEngine: 0.5.0

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: None
    deterministic: False
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2023/02/05 12:17:16 - mmengine - INFO - Config:
default_scope = 'mmcls'
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=10),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(type='CheckpointHook', interval=1),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(type='VisualizationHook', enable=False))
env_cfg = dict(
    cudnn_benchmark=False,
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl'))
vis_backends = [dict(type='LocalVisBackend')]
visualizer = dict(
    type='ClsVisualizer', vis_backends=[dict(type='LocalVisBackend')])
log_level = 'INFO'
load_from = 'resnet50_8xb32_in1k_20210831-ea4938fc.pth'
resume = False
randomness = dict(seed=None, deterministic=False)
model = dict(
    type='ImageClassifier',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(3, ),
        style='pytorch'),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='LinearClsHead',
        num_classes=5,
        in_channels=2048,
        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),
        topk=(1, 5)))
dataset_type = 'ImageNet'
data_preprocessor = dict(
    num_classes=5,
    mean=[123.675, 116.28, 103.53],
    std=[58.395, 57.12, 57.375],
    to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='RandomResizedCrop', scale=224),
    dict(type='RandomFlip', prob=0.5, direction='horizontal'),
    dict(type='PackClsInputs')
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='ResizeEdge', scale=256, edge='short'),
    dict(type='CenterCrop', crop_size=224),
    dict(type='PackClsInputs')
]
train_dataloader = dict(
    pin_memory=True,
    persistent_workers=True,
    collate_fn=dict(type='default_collate'),
    batch_size=8,
    num_workers=2,
    dataset=dict(
        type='ImageNet',
        data_root='data/flower',
        ann_file='meta/train.txt',
        data_prefix='train/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='RandomResizedCrop', scale=224),
            dict(type='RandomFlip', prob=0.5, direction='horizontal'),
            dict(type='PackClsInputs')
        ]),
    sampler=dict(type='DefaultSampler', shuffle=True))
val_dataloader = dict(
    pin_memory=True,
    persistent_workers=True,
    collate_fn=dict(type='default_collate'),
    batch_size=8,
    num_workers=2,
    dataset=dict(
        type='ImageNet',
        data_root='data/flower',
        ann_file='meta/val.txt',
        data_prefix='val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='ResizeEdge', scale=256, edge='short'),
            dict(type='CenterCrop', crop_size=224),
            dict(type='PackClsInputs')
        ]),
    sampler=dict(type='DefaultSampler', shuffle=False))
val_evaluator = dict(type='Accuracy', topk=(1, 5))
test_dataloader = dict(
    pin_memory=True,
    persistent_workers=True,
    collate_fn=dict(type='default_collate'),
    batch_size=8,
    num_workers=2,
    dataset=dict(
        type='ImageNet',
        data_root='data/flower',
        ann_file='meta/val.txt',
        data_prefix='val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='ResizeEdge', scale=256, edge='short'),
            dict(type='CenterCrop', crop_size=224),
            dict(type='PackClsInputs')
        ]),
    sampler=dict(type='DefaultSampler', shuffle=False))
test_evaluator = dict(type='Accuracy', topk=(1, 5))
optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.05, momentum=0.9, weight_decay=0.0001))
param_scheduler = dict(
    type='MultiStepLR', by_epoch=True, milestones=[30, 60, 90], gamma=0.1)
train_cfg = dict(by_epoch=True, max_epochs=5, val_interval=5)
val_cfg = dict()
test_cfg = dict()
auto_scale_lr = dict(base_batch_size=256)
launcher = 'none'
work_dir = './work_dirs/resnet50_1xb8_in1k'

2023/02/05 12:17:16 - mmengine - WARNING - The "visualizer" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:16 - mmengine - WARNING - The "vis_backend" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:16 - mmengine - WARNING - The "model" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:17 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2023/02/05 12:17:17 - mmengine - WARNING - The "hook" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:17 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/02/05 12:17:17 - mmengine - WARNING - The "dataset" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:17 - mmengine - WARNING - The "transform" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:17 - mmengine - WARNING - The "data sampler" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:17 - mmengine - WARNING - The "optimizer wrapper constructor" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:17 - mmengine - WARNING - The "optimizer" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:17 - mmengine - WARNING - The "optimizer_wrapper" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:17 - mmengine - WARNING - The "parameter scheduler" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:17 - mmengine - WARNING - The "metric" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
2023/02/05 12:17:17 - mmengine - WARNING - The "weight initializer" registry in mmcls did not set import location. Fallback to call `mmcls.utils.register_all_modules` instead.
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

head.fc.weight - torch.Size([5, 2048]): 
NormalInit: mean=0, std=0.01, bias=0 

head.fc.bias - torch.Size([5]): 
NormalInit: mean=0, std=0.01, bias=0 
2023/02/05 12:17:17 - mmengine - INFO - Load checkpoint from resnet50_8xb32_in1k_20210831-ea4938fc.pth
2023/02/05 12:17:17 - mmengine - INFO - Checkpoints will be saved to /home/liuyoufu/code/OpenMMLab/mmclassification/work_dirs/resnet50_1xb8_in1k.
2023/02/05 12:17:19 - mmengine - INFO - Epoch(train) [1][ 10/285]  lr: 5.0000e-02  eta: 0:04:54  time: 0.2078  data_time: 0.0074  memory: 983  loss: 9.8520
2023/02/05 12:17:21 - mmengine - INFO - Epoch(train) [1][ 20/285]  lr: 5.0000e-02  eta: 0:03:55  time: 0.1274  data_time: 0.0003  memory: 983  loss: 6.3938
2023/02/05 12:17:22 - mmengine - INFO - Epoch(train) [1][ 30/285]  lr: 5.0000e-02  eta: 0:03:37  time: 0.1327  data_time: 0.0003  memory: 983  loss: 2.1541
2023/02/05 12:17:23 - mmengine - INFO - Epoch(train) [1][ 40/285]  lr: 5.0000e-02  eta: 0:03:28  time: 0.1328  data_time: 0.0004  memory: 983  loss: 2.2128
2023/02/05 12:17:25 - mmengine - INFO - Epoch(train) [1][ 50/285]  lr: 5.0000e-02  eta: 0:03:22  time: 0.1360  data_time: 0.0004  memory: 983  loss: 2.0024
2023/02/05 12:17:26 - mmengine - INFO - Epoch(train) [1][ 60/285]  lr: 5.0000e-02  eta: 0:03:19  time: 0.1402  data_time: 0.0004  memory: 983  loss: 2.3661
2023/02/05 12:17:27 - mmengine - INFO - Epoch(train) [1][ 70/285]  lr: 5.0000e-02  eta: 0:03:15  time: 0.1305  data_time: 0.0003  memory: 983  loss: 2.0641
2023/02/05 12:17:29 - mmengine - INFO - Epoch(train) [1][ 80/285]  lr: 5.0000e-02  eta: 0:03:10  time: 0.1267  data_time: 0.0003  memory: 983  loss: 1.9614
2023/02/05 12:17:30 - mmengine - INFO - Epoch(train) [1][ 90/285]  lr: 5.0000e-02  eta: 0:03:07  time: 0.1267  data_time: 0.0003  memory: 983  loss: 1.6351
2023/02/05 12:17:31 - mmengine - INFO - Epoch(train) [1][100/285]  lr: 5.0000e-02  eta: 0:03:03  time: 0.1266  data_time: 0.0003  memory: 983  loss: 1.5591
2023/02/05 12:17:32 - mmengine - INFO - Epoch(train) [1][110/285]  lr: 5.0000e-02  eta: 0:03:01  time: 0.1268  data_time: 0.0003  memory: 983  loss: 1.6687
2023/02/05 12:17:34 - mmengine - INFO - Epoch(train) [1][120/285]  lr: 5.0000e-02  eta: 0:02:58  time: 0.1268  data_time: 0.0003  memory: 983  loss: 1.6609
2023/02/05 12:17:35 - mmengine - INFO - Epoch(train) [1][130/285]  lr: 5.0000e-02  eta: 0:02:56  time: 0.1267  data_time: 0.0003  memory: 983  loss: 1.7679
2023/02/05 12:17:36 - mmengine - INFO - Epoch(train) [1][140/285]  lr: 5.0000e-02  eta: 0:02:53  time: 0.1265  data_time: 0.0003  memory: 983  loss: 1.6622
2023/02/05 12:17:38 - mmengine - INFO - Epoch(train) [1][150/285]  lr: 5.0000e-02  eta: 0:02:51  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.5386
2023/02/05 12:17:39 - mmengine - INFO - Epoch(train) [1][160/285]  lr: 5.0000e-02  eta: 0:02:49  time: 0.1267  data_time: 0.0003  memory: 983  loss: 1.3935
2023/02/05 12:17:40 - mmengine - INFO - Epoch(train) [1][170/285]  lr: 5.0000e-02  eta: 0:02:47  time: 0.1267  data_time: 0.0003  memory: 983  loss: 1.3961
2023/02/05 12:17:41 - mmengine - INFO - Epoch(train) [1][180/285]  lr: 5.0000e-02  eta: 0:02:46  time: 0.1265  data_time: 0.0003  memory: 983  loss: 1.3694
2023/02/05 12:17:43 - mmengine - INFO - Epoch(train) [1][190/285]  lr: 5.0000e-02  eta: 0:02:44  time: 0.1268  data_time: 0.0003  memory: 983  loss: 1.6164
2023/02/05 12:17:44 - mmengine - INFO - Epoch(train) [1][200/285]  lr: 5.0000e-02  eta: 0:02:42  time: 0.1266  data_time: 0.0003  memory: 983  loss: 1.3759
2023/02/05 12:17:45 - mmengine - INFO - Epoch(train) [1][210/285]  lr: 5.0000e-02  eta: 0:02:40  time: 0.1265  data_time: 0.0003  memory: 983  loss: 1.6268
2023/02/05 12:17:46 - mmengine - INFO - Epoch(train) [1][220/285]  lr: 5.0000e-02  eta: 0:02:39  time: 0.1265  data_time: 0.0003  memory: 983  loss: 1.4537
2023/02/05 12:17:48 - mmengine - INFO - Epoch(train) [1][230/285]  lr: 5.0000e-02  eta: 0:02:37  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.4235
2023/02/05 12:17:49 - mmengine - INFO - Epoch(train) [1][240/285]  lr: 5.0000e-02  eta: 0:02:36  time: 0.1267  data_time: 0.0003  memory: 983  loss: 1.5411
2023/02/05 12:17:50 - mmengine - INFO - Epoch(train) [1][250/285]  lr: 5.0000e-02  eta: 0:02:34  time: 0.1266  data_time: 0.0003  memory: 983  loss: 1.4839
2023/02/05 12:17:51 - mmengine - INFO - Epoch(train) [1][260/285]  lr: 5.0000e-02  eta: 0:02:32  time: 0.1265  data_time: 0.0003  memory: 983  loss: 1.5143
2023/02/05 12:17:53 - mmengine - INFO - Epoch(train) [1][270/285]  lr: 5.0000e-02  eta: 0:02:31  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.5097
2023/02/05 12:17:54 - mmengine - INFO - Epoch(train) [1][280/285]  lr: 5.0000e-02  eta: 0:02:29  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.4765
2023/02/05 12:17:55 - mmengine - INFO - Exp name: resnet50_1xb8_in1k_20230205_121715
2023/02/05 12:17:55 - mmengine - INFO - Saving checkpoint at 1 epochs
2023/02/05 12:17:56 - mmengine - INFO - Epoch(train) [2][ 10/285]  lr: 5.0000e-02  eta: 0:02:27  time: 0.1277  data_time: 0.0016  memory: 983  loss: 1.3469
2023/02/05 12:17:57 - mmengine - INFO - Epoch(train) [2][ 20/285]  lr: 5.0000e-02  eta: 0:02:26  time: 0.1270  data_time: 0.0003  memory: 983  loss: 1.5138
2023/02/05 12:17:59 - mmengine - INFO - Epoch(train) [2][ 30/285]  lr: 5.0000e-02  eta: 0:02:24  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.3703
2023/02/05 12:18:00 - mmengine - INFO - Epoch(train) [2][ 40/285]  lr: 5.0000e-02  eta: 0:02:23  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.3482
2023/02/05 12:18:01 - mmengine - INFO - Epoch(train) [2][ 50/285]  lr: 5.0000e-02  eta: 0:02:22  time: 0.1344  data_time: 0.0004  memory: 983  loss: 1.3744
2023/02/05 12:18:03 - mmengine - INFO - Epoch(train) [2][ 60/285]  lr: 5.0000e-02  eta: 0:02:21  time: 0.1484  data_time: 0.0004  memory: 983  loss: 1.2868
2023/02/05 12:18:04 - mmengine - INFO - Epoch(train) [2][ 70/285]  lr: 5.0000e-02  eta: 0:02:20  time: 0.1454  data_time: 0.0005  memory: 983  loss: 1.6630
2023/02/05 12:18:06 - mmengine - INFO - Epoch(train) [2][ 80/285]  lr: 5.0000e-02  eta: 0:02:19  time: 0.1509  data_time: 0.0004  memory: 983  loss: 1.5089
2023/02/05 12:18:07 - mmengine - INFO - Epoch(train) [2][ 90/285]  lr: 5.0000e-02  eta: 0:02:18  time: 0.1378  data_time: 0.0004  memory: 983  loss: 1.3668
2023/02/05 12:18:09 - mmengine - INFO - Epoch(train) [2][100/285]  lr: 5.0000e-02  eta: 0:02:17  time: 0.1378  data_time: 0.0004  memory: 983  loss: 1.3737
2023/02/05 12:18:10 - mmengine - INFO - Epoch(train) [2][110/285]  lr: 5.0000e-02  eta: 0:02:16  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.3211
2023/02/05 12:18:11 - mmengine - INFO - Epoch(train) [2][120/285]  lr: 5.0000e-02  eta: 0:02:14  time: 0.1270  data_time: 0.0003  memory: 983  loss: 1.2696
2023/02/05 12:18:12 - mmengine - INFO - Epoch(train) [2][130/285]  lr: 5.0000e-02  eta: 0:02:13  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.3730
2023/02/05 12:18:14 - mmengine - INFO - Epoch(train) [2][140/285]  lr: 5.0000e-02  eta: 0:02:11  time: 0.1271  data_time: 0.0003  memory: 983  loss: 1.5792
2023/02/05 12:18:15 - mmengine - INFO - Epoch(train) [2][150/285]  lr: 5.0000e-02  eta: 0:02:10  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.4387
2023/02/05 12:18:16 - mmengine - INFO - Epoch(train) [2][160/285]  lr: 5.0000e-02  eta: 0:02:08  time: 0.1287  data_time: 0.0003  memory: 983  loss: 1.4402
2023/02/05 12:18:18 - mmengine - INFO - Epoch(train) [2][170/285]  lr: 5.0000e-02  eta: 0:02:07  time: 0.1330  data_time: 0.0003  memory: 983  loss: 1.3801
2023/02/05 12:18:19 - mmengine - INFO - Epoch(train) [2][180/285]  lr: 5.0000e-02  eta: 0:02:06  time: 0.1448  data_time: 0.0004  memory: 983  loss: 1.3389
2023/02/05 12:18:20 - mmengine - INFO - Epoch(train) [2][190/285]  lr: 5.0000e-02  eta: 0:02:05  time: 0.1349  data_time: 0.0004  memory: 983  loss: 1.3085
2023/02/05 12:18:22 - mmengine - INFO - Epoch(train) [2][200/285]  lr: 5.0000e-02  eta: 0:02:04  time: 0.1335  data_time: 0.0003  memory: 983  loss: 1.3860
2023/02/05 12:18:23 - mmengine - INFO - Epoch(train) [2][210/285]  lr: 5.0000e-02  eta: 0:02:02  time: 0.1326  data_time: 0.0003  memory: 983  loss: 1.2287
2023/02/05 12:18:24 - mmengine - INFO - Epoch(train) [2][220/285]  lr: 5.0000e-02  eta: 0:02:01  time: 0.1290  data_time: 0.0003  memory: 983  loss: 1.3492
2023/02/05 12:18:26 - mmengine - INFO - Epoch(train) [2][230/285]  lr: 5.0000e-02  eta: 0:01:59  time: 0.1282  data_time: 0.0003  memory: 983  loss: 1.4217
2023/02/05 12:18:27 - mmengine - INFO - Epoch(train) [2][240/285]  lr: 5.0000e-02  eta: 0:01:58  time: 0.1270  data_time: 0.0003  memory: 983  loss: 1.2460
2023/02/05 12:18:28 - mmengine - INFO - Epoch(train) [2][250/285]  lr: 5.0000e-02  eta: 0:01:57  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.3556
2023/02/05 12:18:29 - mmengine - INFO - Epoch(train) [2][260/285]  lr: 5.0000e-02  eta: 0:01:55  time: 0.1273  data_time: 0.0003  memory: 983  loss: 1.2161
2023/02/05 12:18:31 - mmengine - INFO - Epoch(train) [2][270/285]  lr: 5.0000e-02  eta: 0:01:54  time: 0.1275  data_time: 0.0003  memory: 983  loss: 1.2470
2023/02/05 12:18:32 - mmengine - INFO - Epoch(train) [2][280/285]  lr: 5.0000e-02  eta: 0:01:53  time: 0.1271  data_time: 0.0003  memory: 983  loss: 1.2252
2023/02/05 12:18:33 - mmengine - INFO - Exp name: resnet50_1xb8_in1k_20230205_121715
2023/02/05 12:18:33 - mmengine - INFO - Saving checkpoint at 2 epochs
2023/02/05 12:18:34 - mmengine - INFO - Epoch(train) [3][ 10/285]  lr: 5.0000e-02  eta: 0:01:50  time: 0.1296  data_time: 0.0017  memory: 983  loss: 1.3423
2023/02/05 12:18:35 - mmengine - INFO - Epoch(train) [3][ 20/285]  lr: 5.0000e-02  eta: 0:01:49  time: 0.1283  data_time: 0.0003  memory: 983  loss: 1.1579
2023/02/05 12:18:37 - mmengine - INFO - Epoch(train) [3][ 30/285]  lr: 5.0000e-02  eta: 0:01:48  time: 0.1276  data_time: 0.0003  memory: 983  loss: 1.2713
2023/02/05 12:18:38 - mmengine - INFO - Epoch(train) [3][ 40/285]  lr: 5.0000e-02  eta: 0:01:46  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.2385
2023/02/05 12:18:39 - mmengine - INFO - Epoch(train) [3][ 50/285]  lr: 5.0000e-02  eta: 0:01:45  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.3989
2023/02/05 12:18:41 - mmengine - INFO - Epoch(train) [3][ 60/285]  lr: 5.0000e-02  eta: 0:01:44  time: 0.1270  data_time: 0.0003  memory: 983  loss: 1.3828
2023/02/05 12:18:42 - mmengine - INFO - Epoch(train) [3][ 70/285]  lr: 5.0000e-02  eta: 0:01:42  time: 0.1273  data_time: 0.0006  memory: 983  loss: 1.3287
2023/02/05 12:18:43 - mmengine - INFO - Epoch(train) [3][ 80/285]  lr: 5.0000e-02  eta: 0:01:41  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.3259
2023/02/05 12:18:44 - mmengine - INFO - Epoch(train) [3][ 90/285]  lr: 5.0000e-02  eta: 0:01:40  time: 0.1270  data_time: 0.0003  memory: 983  loss: 1.2728
2023/02/05 12:18:46 - mmengine - INFO - Epoch(train) [3][100/285]  lr: 5.0000e-02  eta: 0:01:38  time: 0.1269  data_time: 0.0003  memory: 983  loss: 1.3299
2023/02/05 12:18:47 - mmengine - INFO - Epoch(train) [3][110/285]  lr: 5.0000e-02  eta: 0:01:37  time: 0.1274  data_time: 0.0006  memory: 983  loss: 1.2503
2023/02/05 12:18:48 - mmengine - INFO - Epoch(train) [3][120/285]  lr: 5.0000e-02  eta: 0:01:36  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.2106
2023/02/05 12:18:49 - mmengine - INFO - Epoch(train) [3][130/285]  lr: 5.0000e-02  eta: 0:01:34  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.2042
2023/02/05 12:18:51 - mmengine - INFO - Epoch(train) [3][140/285]  lr: 5.0000e-02  eta: 0:01:33  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.3322
2023/02/05 12:18:52 - mmengine - INFO - Epoch(train) [3][150/285]  lr: 5.0000e-02  eta: 0:01:31  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.1296
2023/02/05 12:18:53 - mmengine - INFO - Epoch(train) [3][160/285]  lr: 5.0000e-02  eta: 0:01:30  time: 0.1274  data_time: 0.0003  memory: 983  loss: 1.4242
2023/02/05 12:18:55 - mmengine - INFO - Epoch(train) [3][170/285]  lr: 5.0000e-02  eta: 0:01:29  time: 0.1276  data_time: 0.0004  memory: 983  loss: 1.3183
2023/02/05 12:18:56 - mmengine - INFO - Epoch(train) [3][180/285]  lr: 5.0000e-02  eta: 0:01:27  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.3921
2023/02/05 12:18:57 - mmengine - INFO - Epoch(train) [3][190/285]  lr: 5.0000e-02  eta: 0:01:26  time: 0.1273  data_time: 0.0003  memory: 983  loss: 1.2210
2023/02/05 12:18:58 - mmengine - INFO - Epoch(train) [3][200/285]  lr: 5.0000e-02  eta: 0:01:25  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.2976
2023/02/05 12:19:00 - mmengine - INFO - Epoch(train) [3][210/285]  lr: 5.0000e-02  eta: 0:01:24  time: 0.1273  data_time: 0.0003  memory: 983  loss: 1.3230
2023/02/05 12:19:01 - mmengine - INFO - Epoch(train) [3][220/285]  lr: 5.0000e-02  eta: 0:01:22  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.2270
2023/02/05 12:19:02 - mmengine - INFO - Epoch(train) [3][230/285]  lr: 5.0000e-02  eta: 0:01:21  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.2099
2023/02/05 12:19:03 - mmengine - INFO - Epoch(train) [3][240/285]  lr: 5.0000e-02  eta: 0:01:20  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.3971
2023/02/05 12:19:05 - mmengine - INFO - Epoch(train) [3][250/285]  lr: 5.0000e-02  eta: 0:01:18  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.1881
2023/02/05 12:19:06 - mmengine - INFO - Epoch(train) [3][260/285]  lr: 5.0000e-02  eta: 0:01:17  time: 0.1271  data_time: 0.0003  memory: 983  loss: 1.1938
2023/02/05 12:19:07 - mmengine - INFO - Epoch(train) [3][270/285]  lr: 5.0000e-02  eta: 0:01:16  time: 0.1270  data_time: 0.0003  memory: 983  loss: 1.1721
2023/02/05 12:19:09 - mmengine - INFO - Epoch(train) [3][280/285]  lr: 5.0000e-02  eta: 0:01:14  time: 0.1285  data_time: 0.0003  memory: 983  loss: 1.2381
2023/02/05 12:19:09 - mmengine - INFO - Exp name: resnet50_1xb8_in1k_20230205_121715
2023/02/05 12:19:09 - mmengine - INFO - Saving checkpoint at 3 epochs
2023/02/05 12:19:11 - mmengine - INFO - Epoch(train) [4][ 10/285]  lr: 5.0000e-02  eta: 0:01:12  time: 0.1357  data_time: 0.0019  memory: 983  loss: 1.3143
2023/02/05 12:19:12 - mmengine - INFO - Epoch(train) [4][ 20/285]  lr: 5.0000e-02  eta: 0:01:11  time: 0.1329  data_time: 0.0004  memory: 983  loss: 1.2840
2023/02/05 12:19:13 - mmengine - INFO - Epoch(train) [4][ 30/285]  lr: 5.0000e-02  eta: 0:01:10  time: 0.1281  data_time: 0.0003  memory: 983  loss: 1.3077
2023/02/05 12:19:15 - mmengine - INFO - Epoch(train) [4][ 40/285]  lr: 5.0000e-02  eta: 0:01:08  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.4188
2023/02/05 12:19:16 - mmengine - INFO - Epoch(train) [4][ 50/285]  lr: 5.0000e-02  eta: 0:01:07  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.2481
2023/02/05 12:19:17 - mmengine - INFO - Epoch(train) [4][ 60/285]  lr: 5.0000e-02  eta: 0:01:06  time: 0.1276  data_time: 0.0003  memory: 983  loss: 1.2210
2023/02/05 12:19:19 - mmengine - INFO - Epoch(train) [4][ 70/285]  lr: 5.0000e-02  eta: 0:01:04  time: 0.1287  data_time: 0.0004  memory: 983  loss: 1.1577
2023/02/05 12:19:20 - mmengine - INFO - Epoch(train) [4][ 80/285]  lr: 5.0000e-02  eta: 0:01:03  time: 0.1289  data_time: 0.0004  memory: 983  loss: 1.1119
2023/02/05 12:19:21 - mmengine - INFO - Epoch(train) [4][ 90/285]  lr: 5.0000e-02  eta: 0:01:02  time: 0.1278  data_time: 0.0003  memory: 983  loss: 1.3478
2023/02/05 12:19:22 - mmengine - INFO - Epoch(train) [4][100/285]  lr: 5.0000e-02  eta: 0:01:01  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.2305
2023/02/05 12:19:24 - mmengine - INFO - Epoch(train) [4][110/285]  lr: 5.0000e-02  eta: 0:00:59  time: 0.1273  data_time: 0.0003  memory: 983  loss: 1.1934
2023/02/05 12:19:25 - mmengine - INFO - Epoch(train) [4][120/285]  lr: 5.0000e-02  eta: 0:00:58  time: 0.1271  data_time: 0.0004  memory: 983  loss: 1.0879
2023/02/05 12:19:26 - mmengine - INFO - Epoch(train) [4][130/285]  lr: 5.0000e-02  eta: 0:00:57  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.2116
2023/02/05 12:19:27 - mmengine - INFO - Epoch(train) [4][140/285]  lr: 5.0000e-02  eta: 0:00:55  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.2567
2023/02/05 12:19:28 - mmengine - INFO - Exp name: resnet50_1xb8_in1k_20230205_121715
2023/02/05 12:19:29 - mmengine - INFO - Epoch(train) [4][150/285]  lr: 5.0000e-02  eta: 0:00:54  time: 0.1278  data_time: 0.0003  memory: 983  loss: 1.3038
2023/02/05 12:19:30 - mmengine - INFO - Epoch(train) [4][160/285]  lr: 5.0000e-02  eta: 0:00:53  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.1599
2023/02/05 12:19:31 - mmengine - INFO - Epoch(train) [4][170/285]  lr: 5.0000e-02  eta: 0:00:51  time: 0.1271  data_time: 0.0003  memory: 983  loss: 1.2111
2023/02/05 12:19:33 - mmengine - INFO - Epoch(train) [4][180/285]  lr: 5.0000e-02  eta: 0:00:50  time: 0.1280  data_time: 0.0003  memory: 983  loss: 1.2313
2023/02/05 12:19:34 - mmengine - INFO - Epoch(train) [4][190/285]  lr: 5.0000e-02  eta: 0:00:49  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.3198
2023/02/05 12:19:35 - mmengine - INFO - Epoch(train) [4][200/285]  lr: 5.0000e-02  eta: 0:00:47  time: 0.1273  data_time: 0.0003  memory: 983  loss: 1.1287
2023/02/05 12:19:36 - mmengine - INFO - Epoch(train) [4][210/285]  lr: 5.0000e-02  eta: 0:00:46  time: 0.1271  data_time: 0.0003  memory: 983  loss: 1.2512
2023/02/05 12:19:38 - mmengine - INFO - Epoch(train) [4][220/285]  lr: 5.0000e-02  eta: 0:00:45  time: 0.1273  data_time: 0.0003  memory: 983  loss: 1.1795
2023/02/05 12:19:39 - mmengine - INFO - Epoch(train) [4][230/285]  lr: 5.0000e-02  eta: 0:00:44  time: 0.1273  data_time: 0.0004  memory: 983  loss: 1.1028
2023/02/05 12:19:40 - mmengine - INFO - Epoch(train) [4][240/285]  lr: 5.0000e-02  eta: 0:00:42  time: 0.1271  data_time: 0.0003  memory: 983  loss: 1.0346
2023/02/05 12:19:41 - mmengine - INFO - Epoch(train) [4][250/285]  lr: 5.0000e-02  eta: 0:00:41  time: 0.1270  data_time: 0.0003  memory: 983  loss: 1.4275
2023/02/05 12:19:43 - mmengine - INFO - Epoch(train) [4][260/285]  lr: 5.0000e-02  eta: 0:00:40  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.0457
2023/02/05 12:19:44 - mmengine - INFO - Epoch(train) [4][270/285]  lr: 5.0000e-02  eta: 0:00:38  time: 0.1273  data_time: 0.0003  memory: 983  loss: 1.3018
2023/02/05 12:19:45 - mmengine - INFO - Epoch(train) [4][280/285]  lr: 5.0000e-02  eta: 0:00:37  time: 0.1276  data_time: 0.0003  memory: 983  loss: 1.1760
2023/02/05 12:19:46 - mmengine - INFO - Exp name: resnet50_1xb8_in1k_20230205_121715
2023/02/05 12:19:46 - mmengine - INFO - Saving checkpoint at 4 epochs
2023/02/05 12:19:48 - mmengine - INFO - Epoch(train) [5][ 10/285]  lr: 5.0000e-02  eta: 0:00:35  time: 0.1300  data_time: 0.0015  memory: 983  loss: 1.0894
2023/02/05 12:19:49 - mmengine - INFO - Epoch(train) [5][ 20/285]  lr: 5.0000e-02  eta: 0:00:34  time: 0.1285  data_time: 0.0004  memory: 983  loss: 1.4140
2023/02/05 12:19:50 - mmengine - INFO - Epoch(train) [5][ 30/285]  lr: 5.0000e-02  eta: 0:00:33  time: 0.1278  data_time: 0.0004  memory: 983  loss: 1.2033
2023/02/05 12:19:51 - mmengine - INFO - Epoch(train) [5][ 40/285]  lr: 5.0000e-02  eta: 0:00:31  time: 0.1289  data_time: 0.0004  memory: 983  loss: 1.3017
2023/02/05 12:19:53 - mmengine - INFO - Epoch(train) [5][ 50/285]  lr: 5.0000e-02  eta: 0:00:30  time: 0.1293  data_time: 0.0004  memory: 983  loss: 1.1639
2023/02/05 12:19:54 - mmengine - INFO - Epoch(train) [5][ 60/285]  lr: 5.0000e-02  eta: 0:00:29  time: 0.1281  data_time: 0.0004  memory: 983  loss: 1.3200
2023/02/05 12:19:55 - mmengine - INFO - Epoch(train) [5][ 70/285]  lr: 5.0000e-02  eta: 0:00:27  time: 0.1288  data_time: 0.0004  memory: 983  loss: 1.2515
2023/02/05 12:19:56 - mmengine - INFO - Epoch(train) [5][ 80/285]  lr: 5.0000e-02  eta: 0:00:26  time: 0.1280  data_time: 0.0003  memory: 983  loss: 1.2509
2023/02/05 12:19:58 - mmengine - INFO - Epoch(train) [5][ 90/285]  lr: 5.0000e-02  eta: 0:00:25  time: 0.1288  data_time: 0.0004  memory: 983  loss: 1.1703
2023/02/05 12:19:59 - mmengine - INFO - Epoch(train) [5][100/285]  lr: 5.0000e-02  eta: 0:00:23  time: 0.1296  data_time: 0.0004  memory: 983  loss: 1.2054
2023/02/05 12:20:00 - mmengine - INFO - Epoch(train) [5][110/285]  lr: 5.0000e-02  eta: 0:00:22  time: 0.1287  data_time: 0.0003  memory: 983  loss: 1.1954
2023/02/05 12:20:02 - mmengine - INFO - Epoch(train) [5][120/285]  lr: 5.0000e-02  eta: 0:00:21  time: 0.1277  data_time: 0.0004  memory: 983  loss: 1.2279
2023/02/05 12:20:03 - mmengine - INFO - Epoch(train) [5][130/285]  lr: 5.0000e-02  eta: 0:00:20  time: 0.1282  data_time: 0.0003  memory: 983  loss: 1.0310
2023/02/05 12:20:04 - mmengine - INFO - Epoch(train) [5][140/285]  lr: 5.0000e-02  eta: 0:00:18  time: 0.1309  data_time: 0.0005  memory: 983  loss: 1.0260
2023/02/05 12:20:06 - mmengine - INFO - Epoch(train) [5][150/285]  lr: 5.0000e-02  eta: 0:00:17  time: 0.1282  data_time: 0.0004  memory: 983  loss: 1.2161
2023/02/05 12:20:07 - mmengine - INFO - Epoch(train) [5][160/285]  lr: 5.0000e-02  eta: 0:00:16  time: 0.1279  data_time: 0.0003  memory: 983  loss: 1.3485
2023/02/05 12:20:08 - mmengine - INFO - Epoch(train) [5][170/285]  lr: 5.0000e-02  eta: 0:00:14  time: 0.1291  data_time: 0.0004  memory: 983  loss: 1.2538
2023/02/05 12:20:09 - mmengine - INFO - Epoch(train) [5][180/285]  lr: 5.0000e-02  eta: 0:00:13  time: 0.1286  data_time: 0.0004  memory: 983  loss: 1.2295
2023/02/05 12:20:11 - mmengine - INFO - Epoch(train) [5][190/285]  lr: 5.0000e-02  eta: 0:00:12  time: 0.1291  data_time: 0.0004  memory: 983  loss: 1.3306
2023/02/05 12:20:12 - mmengine - INFO - Epoch(train) [5][200/285]  lr: 5.0000e-02  eta: 0:00:10  time: 0.1284  data_time: 0.0004  memory: 983  loss: 1.3102
2023/02/05 12:20:13 - mmengine - INFO - Epoch(train) [5][210/285]  lr: 5.0000e-02  eta: 0:00:09  time: 0.1275  data_time: 0.0003  memory: 983  loss: 1.2268
2023/02/05 12:20:15 - mmengine - INFO - Epoch(train) [5][220/285]  lr: 5.0000e-02  eta: 0:00:08  time: 0.1280  data_time: 0.0004  memory: 983  loss: 1.0878
2023/02/05 12:20:16 - mmengine - INFO - Epoch(train) [5][230/285]  lr: 5.0000e-02  eta: 0:00:07  time: 0.1272  data_time: 0.0003  memory: 983  loss: 1.2178
2023/02/05 12:20:17 - mmengine - INFO - Epoch(train) [5][240/285]  lr: 5.0000e-02  eta: 0:00:05  time: 0.1277  data_time: 0.0003  memory: 983  loss: 1.1197
2023/02/05 12:20:18 - mmengine - INFO - Epoch(train) [5][250/285]  lr: 5.0000e-02  eta: 0:00:04  time: 0.1284  data_time: 0.0004  memory: 983  loss: 1.1002
2023/02/05 12:20:20 - mmengine - INFO - Epoch(train) [5][260/285]  lr: 5.0000e-02  eta: 0:00:03  time: 0.1294  data_time: 0.0004  memory: 983  loss: 1.2287
2023/02/05 12:20:21 - mmengine - INFO - Epoch(train) [5][270/285]  lr: 5.0000e-02  eta: 0:00:01  time: 0.1283  data_time: 0.0004  memory: 983  loss: 1.3393
2023/02/05 12:20:22 - mmengine - INFO - Epoch(train) [5][280/285]  lr: 5.0000e-02  eta: 0:00:00  time: 0.1287  data_time: 0.0004  memory: 983  loss: 1.1977
2023/02/05 12:20:23 - mmengine - INFO - Exp name: resnet50_1xb8_in1k_20230205_121715
2023/02/05 12:20:23 - mmengine - INFO - Saving checkpoint at 5 epochs
2023/02/05 12:20:24 - mmengine - INFO - Epoch(val) [5][10/72]    eta: 0:00:02  time: 0.0406  data_time: 0.0051  memory: 983  
2023/02/05 12:20:24 - mmengine - INFO - Epoch(val) [5][20/72]    eta: 0:00:01  time: 0.0362  data_time: 0.0002  memory: 361  
2023/02/05 12:20:24 - mmengine - INFO - Epoch(val) [5][30/72]    eta: 0:00:01  time: 0.0355  data_time: 0.0002  memory: 361  
2023/02/05 12:20:25 - mmengine - INFO - Epoch(val) [5][40/72]    eta: 0:00:01  time: 0.0354  data_time: 0.0002  memory: 361  
2023/02/05 12:20:25 - mmengine - INFO - Epoch(val) [5][50/72]    eta: 0:00:00  time: 0.0353  data_time: 0.0001  memory: 361  
2023/02/05 12:20:25 - mmengine - INFO - Epoch(val) [5][60/72]    eta: 0:00:00  time: 0.0353  data_time: 0.0001  memory: 361  
2023/02/05 12:20:26 - mmengine - INFO - Epoch(val) [5][70/72]    eta: 0:00:00  time: 0.0355  data_time: 0.0001  memory: 361  
2023/02/05 12:20:26 - mmengine - INFO - Epoch(val) [5][72/72]  accuracy/top1: 55.9441  accuracy/top5: 100.0000
